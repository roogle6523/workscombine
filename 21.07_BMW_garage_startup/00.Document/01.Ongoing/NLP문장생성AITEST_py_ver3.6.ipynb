{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "import os\r\n",
    "import sys"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "print(sys.version)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "import re\r\n",
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "!pip install torch"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\com\\anaconda3\\envs\\py36_env\\lib\\site-packages (1.9.0)\n",
      "Requirement already satisfied: dataclasses in c:\\users\\com\\anaconda3\\envs\\py36_env\\lib\\site-packages (from torch) (0.8)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\com\\anaconda3\\envs\\py36_env\\lib\\site-packages (from torch) (3.10.0.0)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "!pip install MXNet"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: MXNet in c:\\users\\com\\anaconda3\\envs\\py36_env\\lib\\site-packages (1.7.0.post2)\n",
      "Collecting numpy<1.17.0,>=1.8.2\n",
      "  Using cached numpy-1.16.6-cp36-cp36m-win_amd64.whl (11.9 MB)\n",
      "Requirement already satisfied: requests<2.19.0,>=2.18.4 in c:\\users\\com\\anaconda3\\envs\\py36_env\\lib\\site-packages (from MXNet) (2.18.4)\n",
      "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in c:\\users\\com\\anaconda3\\envs\\py36_env\\lib\\site-packages (from MXNet) (0.8.4)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\com\\anaconda3\\envs\\py36_env\\lib\\site-packages (from requests<2.19.0,>=2.18.4->MXNet) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in c:\\users\\com\\anaconda3\\envs\\py36_env\\lib\\site-packages (from requests<2.19.0,>=2.18.4->MXNet) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in c:\\users\\com\\anaconda3\\envs\\py36_env\\lib\\site-packages (from requests<2.19.0,>=2.18.4->MXNet) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\com\\anaconda3\\envs\\py36_env\\lib\\site-packages (from requests<2.19.0,>=2.18.4->MXNet) (2021.5.30)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n",
      "Successfully installed numpy-1.16.6\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "transformers 4.9.1 requires numpy>=1.17, but you have numpy 1.16.6 which is incompatible.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "!pip3 install --upgrade mxnet gluonnlp"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: mxnet in c:\\users\\com\\anaconda3\\envs\\py36_env\\lib\\site-packages (1.7.0.post2)\n",
      "Collecting gluonnlp\n",
      "  Using cached gluonnlp-0.10.0.tar.gz (344 kB)\n",
      "Requirement already satisfied: numpy<1.17.0,>=1.8.2 in c:\\users\\com\\anaconda3\\envs\\py36_env\\lib\\site-packages (from mxnet) (1.16.6)\n",
      "Requirement already satisfied: requests<2.19.0,>=2.18.4 in c:\\users\\com\\anaconda3\\envs\\py36_env\\lib\\site-packages (from mxnet) (2.18.4)\n",
      "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in c:\\users\\com\\anaconda3\\envs\\py36_env\\lib\\site-packages (from mxnet) (0.8.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in c:\\users\\com\\anaconda3\\envs\\py36_env\\lib\\site-packages (from requests<2.19.0,>=2.18.4->mxnet) (2.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\com\\anaconda3\\envs\\py36_env\\lib\\site-packages (from requests<2.19.0,>=2.18.4->mxnet) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in c:\\users\\com\\anaconda3\\envs\\py36_env\\lib\\site-packages (from requests<2.19.0,>=2.18.4->mxnet) (1.22)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\com\\anaconda3\\envs\\py36_env\\lib\\site-packages (from requests<2.19.0,>=2.18.4->mxnet) (3.0.4)\n",
      "Requirement already satisfied: cython in c:\\users\\com\\anaconda3\\envs\\py36_env\\lib\\site-packages (from gluonnlp) (0.29.24)\n",
      "Requirement already satisfied: packaging in c:\\users\\com\\anaconda3\\envs\\py36_env\\lib\\site-packages (from gluonnlp) (21.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\com\\anaconda3\\envs\\py36_env\\lib\\site-packages (from packaging->gluonnlp) (2.4.7)\n",
      "Building wheels for collected packages: gluonnlp\n",
      "  Building wheel for gluonnlp (setup.py): started\n",
      "  Building wheel for gluonnlp (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for gluonnlp\n",
      "Failed to build gluonnlp\n",
      "Installing collected packages: gluonnlp\n",
      "    Running setup.py install for gluonnlp: started\n",
      "    Running setup.py install for gluonnlp: finished with status 'error'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'C:\\Users\\com\\anaconda3\\envs\\py36_env\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\com\\\\AppData\\\\Local\\\\Temp\\\\pip-install-w22sg0bz\\\\gluonnlp_367c5bf97f2344abafb3d8e16c604663\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\com\\\\AppData\\\\Local\\\\Temp\\\\pip-install-w22sg0bz\\\\gluonnlp_367c5bf97f2344abafb3d8e16c604663\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d 'C:\\Users\\com\\AppData\\Local\\Temp\\pip-wheel-2kc3a3jh'\n",
      "       cwd: C:\\Users\\com\\AppData\\Local\\Temp\\pip-install-w22sg0bz\\gluonnlp_367c5bf97f2344abafb3d8e16c604663\\\n",
      "  Complete output (123 lines):\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-3.6\n",
      "  creating build\\lib.win-amd64-3.6\\gluonnlp\n",
      "  copying src\\gluonnlp\\base.py -> build\\lib.win-amd64-3.6\\gluonnlp\n",
      "  copying src\\gluonnlp\\_constants.py -> build\\lib.win-amd64-3.6\\gluonnlp\n",
      "  copying src\\gluonnlp\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\n",
      "  creating build\\lib.win-amd64-3.6\\gluonnlp\\calibration\n",
      "  copying src\\gluonnlp\\calibration\\collector.py -> build\\lib.win-amd64-3.6\\gluonnlp\\calibration\n",
      "  copying src\\gluonnlp\\calibration\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\calibration\n",
      "  creating build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\baidu_ernie_data.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\candidate_sampler.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\classification.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\conll.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\dataloader.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\dataset.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\datasetloader.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\glue.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\intent_slot.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\question_answering.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\registry.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\sampler.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\sentiment.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\stream.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\super_glue.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\transforms.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\translation.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\utils.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\word_embedding_evaluation.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "  creating build\\lib.win-amd64-3.6\\gluonnlp\\embedding\n",
      "  copying src\\gluonnlp\\embedding\\evaluation.py -> build\\lib.win-amd64-3.6\\gluonnlp\\embedding\n",
      "  copying src\\gluonnlp\\embedding\\token_embedding.py -> build\\lib.win-amd64-3.6\\gluonnlp\\embedding\n",
      "  copying src\\gluonnlp\\embedding\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\embedding\n",
      "  creating build\\lib.win-amd64-3.6\\gluonnlp\\initializer\n",
      "  copying src\\gluonnlp\\initializer\\initializer.py -> build\\lib.win-amd64-3.6\\gluonnlp\\initializer\n",
      "  copying src\\gluonnlp\\initializer\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\initializer\n",
      "  creating build\\lib.win-amd64-3.6\\gluonnlp\\loss\n",
      "  copying src\\gluonnlp\\loss\\activation_regularizer.py -> build\\lib.win-amd64-3.6\\gluonnlp\\loss\n",
      "  copying src\\gluonnlp\\loss\\label_smoothing.py -> build\\lib.win-amd64-3.6\\gluonnlp\\loss\n",
      "  copying src\\gluonnlp\\loss\\loss.py -> build\\lib.win-amd64-3.6\\gluonnlp\\loss\n",
      "  copying src\\gluonnlp\\loss\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\loss\n",
      "  creating build\\lib.win-amd64-3.6\\gluonnlp\\metric\n",
      "  copying src\\gluonnlp\\metric\\length_normalized_loss.py -> build\\lib.win-amd64-3.6\\gluonnlp\\metric\n",
      "  copying src\\gluonnlp\\metric\\masked_accuracy.py -> build\\lib.win-amd64-3.6\\gluonnlp\\metric\n",
      "  copying src\\gluonnlp\\metric\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\metric\n",
      "  creating build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\attention_cell.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\bert.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\bilm_encoder.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\block.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\convolutional_encoder.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\elmo.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\highway.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\info.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\language_model.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\lstmpcellwithclip.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\parameter.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\sampled_block.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\seq2seq_encoder_decoder.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\sequence_sampler.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\transformer.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\translation.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\utils.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "  creating build\\lib.win-amd64-3.6\\gluonnlp\\optimizer\n",
      "  copying src\\gluonnlp\\optimizer\\bert_adam.py -> build\\lib.win-amd64-3.6\\gluonnlp\\optimizer\n",
      "  copying src\\gluonnlp\\optimizer\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\optimizer\n",
      "  creating build\\lib.win-amd64-3.6\\gluonnlp\\utils\n",
      "  copying src\\gluonnlp\\utils\\files.py -> build\\lib.win-amd64-3.6\\gluonnlp\\utils\n",
      "  copying src\\gluonnlp\\utils\\parallel.py -> build\\lib.win-amd64-3.6\\gluonnlp\\utils\n",
      "  copying src\\gluonnlp\\utils\\parameter.py -> build\\lib.win-amd64-3.6\\gluonnlp\\utils\n",
      "  copying src\\gluonnlp\\utils\\seed.py -> build\\lib.win-amd64-3.6\\gluonnlp\\utils\n",
      "  copying src\\gluonnlp\\utils\\version.py -> build\\lib.win-amd64-3.6\\gluonnlp\\utils\n",
      "  copying src\\gluonnlp\\utils\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\utils\n",
      "  creating build\\lib.win-amd64-3.6\\gluonnlp\\vocab\n",
      "  copying src\\gluonnlp\\vocab\\bert.py -> build\\lib.win-amd64-3.6\\gluonnlp\\vocab\n",
      "  copying src\\gluonnlp\\vocab\\elmo.py -> build\\lib.win-amd64-3.6\\gluonnlp\\vocab\n",
      "  copying src\\gluonnlp\\vocab\\subwords.py -> build\\lib.win-amd64-3.6\\gluonnlp\\vocab\n",
      "  copying src\\gluonnlp\\vocab\\vocab.py -> build\\lib.win-amd64-3.6\\gluonnlp\\vocab\n",
      "  copying src\\gluonnlp\\vocab\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\vocab\n",
      "  creating build\\lib.win-amd64-3.6\\gluonnlp\\data\\batchify\n",
      "  copying src\\gluonnlp\\data\\batchify\\batchify.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\\batchify\n",
      "  copying src\\gluonnlp\\data\\batchify\\embedding.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\\batchify\n",
      "  copying src\\gluonnlp\\data\\batchify\\language_model.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\\batchify\n",
      "  copying src\\gluonnlp\\data\\batchify\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\\batchify\n",
      "  creating build\\lib.win-amd64-3.6\\gluonnlp\\data\\bert\n",
      "  copying src\\gluonnlp\\data\\bert\\glue.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\\bert\n",
      "  copying src\\gluonnlp\\data\\bert\\squad.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\\bert\n",
      "  copying src\\gluonnlp\\data\\bert\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\\bert\n",
      "  creating build\\lib.win-amd64-3.6\\gluonnlp\\data\\corpora\n",
      "  copying src\\gluonnlp\\data\\corpora\\google_billion_word.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\\corpora\n",
      "  copying src\\gluonnlp\\data\\corpora\\large_text_compression_benchmark.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\\corpora\n",
      "  copying src\\gluonnlp\\data\\corpora\\wikitext.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\\corpora\n",
      "  copying src\\gluonnlp\\data\\corpora\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\\corpora\n",
      "  creating build\\lib.win-amd64-3.6\\gluonnlp\\data\\xlnet\n",
      "  copying src\\gluonnlp\\data\\xlnet\\squad.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\\xlnet\n",
      "  copying src\\gluonnlp\\data\\xlnet\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\\xlnet\n",
      "  creating build\\lib.win-amd64-3.6\\gluonnlp\\model\\train\n",
      "  copying src\\gluonnlp\\model\\train\\cache.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\\train\n",
      "  copying src\\gluonnlp\\model\\train\\embedding.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\\train\n",
      "  copying src\\gluonnlp\\model\\train\\language_model.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\\train\n",
      "  copying src\\gluonnlp\\model\\train\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\\train\n",
      "  running egg_info\n",
      "  writing src\\gluonnlp.egg-info\\PKG-INFO\n",
      "  writing dependency_links to src\\gluonnlp.egg-info\\dependency_links.txt\n",
      "  writing requirements to src\\gluonnlp.egg-info\\requires.txt\n",
      "  writing top-level names to src\\gluonnlp.egg-info\\top_level.txt\n",
      "  reading manifest file 'src\\gluonnlp.egg-info\\SOURCES.txt'\n",
      "  reading manifest template 'MANIFEST.in'\n",
      "  warning: no files found matching '*.py' under directory 'gluonnlp'\n",
      "  warning: no previously-included files matching '*' found under directory 'tests'\n",
      "  warning: no previously-included files matching '*' found under directory 'scripts'\n",
      "  writing manifest file 'src\\gluonnlp.egg-info\\SOURCES.txt'\n",
      "  copying src\\gluonnlp\\data\\fast_bert_tokenizer.c -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\fast_bert_tokenizer.pyx -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "  running build_ext\n",
      "  skipping 'src/gluonnlp/data\\fast_bert_tokenizer.c' Cython extension (up-to-date)\n",
      "  building 'gluonnlp.data.fast_bert_tokenizer' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for gluonnlp\n",
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'C:\\Users\\com\\anaconda3\\envs\\py36_env\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\com\\\\AppData\\\\Local\\\\Temp\\\\pip-install-w22sg0bz\\\\gluonnlp_367c5bf97f2344abafb3d8e16c604663\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\com\\\\AppData\\\\Local\\\\Temp\\\\pip-install-w22sg0bz\\\\gluonnlp_367c5bf97f2344abafb3d8e16c604663\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\com\\AppData\\Local\\Temp\\pip-record-e3pec7wq\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\Users\\com\\anaconda3\\envs\\py36_env\\Include\\gluonnlp'\n",
      "         cwd: C:\\Users\\com\\AppData\\Local\\Temp\\pip-install-w22sg0bz\\gluonnlp_367c5bf97f2344abafb3d8e16c604663\\\n",
      "    Complete output (123 lines):\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build\\lib.win-amd64-3.6\n",
      "    creating build\\lib.win-amd64-3.6\\gluonnlp\n",
      "    copying src\\gluonnlp\\base.py -> build\\lib.win-amd64-3.6\\gluonnlp\n",
      "    copying src\\gluonnlp\\_constants.py -> build\\lib.win-amd64-3.6\\gluonnlp\n",
      "    copying src\\gluonnlp\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\n",
      "    creating build\\lib.win-amd64-3.6\\gluonnlp\\calibration\n",
      "    copying src\\gluonnlp\\calibration\\collector.py -> build\\lib.win-amd64-3.6\\gluonnlp\\calibration\n",
      "    copying src\\gluonnlp\\calibration\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\calibration\n",
      "    creating build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\baidu_ernie_data.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\candidate_sampler.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\classification.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\conll.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\dataloader.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\dataset.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\datasetloader.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\glue.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\intent_slot.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\question_answering.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\registry.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\sampler.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\sentiment.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\stream.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\super_glue.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\transforms.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\translation.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\utils.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\word_embedding_evaluation.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "    creating build\\lib.win-amd64-3.6\\gluonnlp\\embedding\n",
      "    copying src\\gluonnlp\\embedding\\evaluation.py -> build\\lib.win-amd64-3.6\\gluonnlp\\embedding\n",
      "    copying src\\gluonnlp\\embedding\\token_embedding.py -> build\\lib.win-amd64-3.6\\gluonnlp\\embedding\n",
      "    copying src\\gluonnlp\\embedding\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\embedding\n",
      "    creating build\\lib.win-amd64-3.6\\gluonnlp\\initializer\n",
      "    copying src\\gluonnlp\\initializer\\initializer.py -> build\\lib.win-amd64-3.6\\gluonnlp\\initializer\n",
      "    copying src\\gluonnlp\\initializer\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\initializer\n",
      "    creating build\\lib.win-amd64-3.6\\gluonnlp\\loss\n",
      "    copying src\\gluonnlp\\loss\\activation_regularizer.py -> build\\lib.win-amd64-3.6\\gluonnlp\\loss\n",
      "    copying src\\gluonnlp\\loss\\label_smoothing.py -> build\\lib.win-amd64-3.6\\gluonnlp\\loss\n",
      "    copying src\\gluonnlp\\loss\\loss.py -> build\\lib.win-amd64-3.6\\gluonnlp\\loss\n",
      "    copying src\\gluonnlp\\loss\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\loss\n",
      "    creating build\\lib.win-amd64-3.6\\gluonnlp\\metric\n",
      "    copying src\\gluonnlp\\metric\\length_normalized_loss.py -> build\\lib.win-amd64-3.6\\gluonnlp\\metric\n",
      "    copying src\\gluonnlp\\metric\\masked_accuracy.py -> build\\lib.win-amd64-3.6\\gluonnlp\\metric\n",
      "    copying src\\gluonnlp\\metric\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\metric\n",
      "    creating build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\attention_cell.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\bert.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\bilm_encoder.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\block.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\convolutional_encoder.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\elmo.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\highway.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\info.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\language_model.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\lstmpcellwithclip.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\parameter.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\sampled_block.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\seq2seq_encoder_decoder.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\sequence_sampler.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\transformer.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\translation.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\utils.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\n",
      "    creating build\\lib.win-amd64-3.6\\gluonnlp\\optimizer\n",
      "    copying src\\gluonnlp\\optimizer\\bert_adam.py -> build\\lib.win-amd64-3.6\\gluonnlp\\optimizer\n",
      "    copying src\\gluonnlp\\optimizer\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\optimizer\n",
      "    creating build\\lib.win-amd64-3.6\\gluonnlp\\utils\n",
      "    copying src\\gluonnlp\\utils\\files.py -> build\\lib.win-amd64-3.6\\gluonnlp\\utils\n",
      "    copying src\\gluonnlp\\utils\\parallel.py -> build\\lib.win-amd64-3.6\\gluonnlp\\utils\n",
      "    copying src\\gluonnlp\\utils\\parameter.py -> build\\lib.win-amd64-3.6\\gluonnlp\\utils\n",
      "    copying src\\gluonnlp\\utils\\seed.py -> build\\lib.win-amd64-3.6\\gluonnlp\\utils\n",
      "    copying src\\gluonnlp\\utils\\version.py -> build\\lib.win-amd64-3.6\\gluonnlp\\utils\n",
      "    copying src\\gluonnlp\\utils\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\utils\n",
      "    creating build\\lib.win-amd64-3.6\\gluonnlp\\vocab\n",
      "    copying src\\gluonnlp\\vocab\\bert.py -> build\\lib.win-amd64-3.6\\gluonnlp\\vocab\n",
      "    copying src\\gluonnlp\\vocab\\elmo.py -> build\\lib.win-amd64-3.6\\gluonnlp\\vocab\n",
      "    copying src\\gluonnlp\\vocab\\subwords.py -> build\\lib.win-amd64-3.6\\gluonnlp\\vocab\n",
      "    copying src\\gluonnlp\\vocab\\vocab.py -> build\\lib.win-amd64-3.6\\gluonnlp\\vocab\n",
      "    copying src\\gluonnlp\\vocab\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\vocab\n",
      "    creating build\\lib.win-amd64-3.6\\gluonnlp\\data\\batchify\n",
      "    copying src\\gluonnlp\\data\\batchify\\batchify.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\\batchify\n",
      "    copying src\\gluonnlp\\data\\batchify\\embedding.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\\batchify\n",
      "    copying src\\gluonnlp\\data\\batchify\\language_model.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\\batchify\n",
      "    copying src\\gluonnlp\\data\\batchify\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\\batchify\n",
      "    creating build\\lib.win-amd64-3.6\\gluonnlp\\data\\bert\n",
      "    copying src\\gluonnlp\\data\\bert\\glue.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\\bert\n",
      "    copying src\\gluonnlp\\data\\bert\\squad.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\\bert\n",
      "    copying src\\gluonnlp\\data\\bert\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\\bert\n",
      "    creating build\\lib.win-amd64-3.6\\gluonnlp\\data\\corpora\n",
      "    copying src\\gluonnlp\\data\\corpora\\google_billion_word.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\\corpora\n",
      "    copying src\\gluonnlp\\data\\corpora\\large_text_compression_benchmark.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\\corpora\n",
      "    copying src\\gluonnlp\\data\\corpora\\wikitext.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\\corpora\n",
      "    copying src\\gluonnlp\\data\\corpora\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\\corpora\n",
      "    creating build\\lib.win-amd64-3.6\\gluonnlp\\data\\xlnet\n",
      "    copying src\\gluonnlp\\data\\xlnet\\squad.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\\xlnet\n",
      "    copying src\\gluonnlp\\data\\xlnet\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\data\\xlnet\n",
      "    creating build\\lib.win-amd64-3.6\\gluonnlp\\model\\train\n",
      "    copying src\\gluonnlp\\model\\train\\cache.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\\train\n",
      "    copying src\\gluonnlp\\model\\train\\embedding.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\\train\n",
      "    copying src\\gluonnlp\\model\\train\\language_model.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\\train\n",
      "    copying src\\gluonnlp\\model\\train\\__init__.py -> build\\lib.win-amd64-3.6\\gluonnlp\\model\\train\n",
      "    running egg_info\n",
      "    writing src\\gluonnlp.egg-info\\PKG-INFO\n",
      "    writing dependency_links to src\\gluonnlp.egg-info\\dependency_links.txt\n",
      "    writing requirements to src\\gluonnlp.egg-info\\requires.txt\n",
      "    writing top-level names to src\\gluonnlp.egg-info\\top_level.txt\n",
      "    reading manifest file 'src\\gluonnlp.egg-info\\SOURCES.txt'\n",
      "    reading manifest template 'MANIFEST.in'\n",
      "    warning: no files found matching '*.py' under directory 'gluonnlp'\n",
      "    warning: no previously-included files matching '*' found under directory 'tests'\n",
      "    warning: no previously-included files matching '*' found under directory 'scripts'\n",
      "    writing manifest file 'src\\gluonnlp.egg-info\\SOURCES.txt'\n",
      "    copying src\\gluonnlp\\data\\fast_bert_tokenizer.c -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\fast_bert_tokenizer.pyx -> build\\lib.win-amd64-3.6\\gluonnlp\\data\n",
      "    running build_ext\n",
      "    skipping 'src/gluonnlp/data\\fast_bert_tokenizer.c' Cython extension (up-to-date)\n",
      "    building 'gluonnlp.data.fast_bert_tokenizer' extension\n",
      "    error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "    ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: 'C:\\Users\\com\\anaconda3\\envs\\py36_env\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\com\\\\AppData\\\\Local\\\\Temp\\\\pip-install-w22sg0bz\\\\gluonnlp_367c5bf97f2344abafb3d8e16c604663\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\com\\\\AppData\\\\Local\\\\Temp\\\\pip-install-w22sg0bz\\\\gluonnlp_367c5bf97f2344abafb3d8e16c604663\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\com\\AppData\\Local\\Temp\\pip-record-e3pec7wq\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\Users\\com\\anaconda3\\envs\\py36_env\\Include\\gluonnlp' Check the logs for full command output.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "!pip install python3-dev"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement python3-dev (from versions: none)\n",
      "ERROR: No matching distribution found for python3-dev\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "pip install --upgrade mxnet>=1.6.0"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install sentencepiece "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting sentencepiece\n",
      "  Using cached sentencepiece-0.1.96-cp36-cp36m-win_amd64.whl (1.1 MB)\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.96\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install transformers "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.9.1-py3-none-any.whl (2.6 MB)\n",
      "Collecting tqdm>=4.27\n",
      "  Using cached tqdm-4.61.2-py2.py3-none-any.whl (76 kB)\n",
      "Collecting huggingface-hub==0.0.12\n",
      "  Using cached huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\com\\anaconda3\\envs\\py36_env\\lib\\site-packages (from transformers) (2.18.4)\n",
      "Requirement already satisfied: dataclasses in c:\\users\\com\\anaconda3\\envs\\py36_env\\lib\\site-packages (from transformers) (0.8)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\com\\anaconda3\\envs\\py36_env\\lib\\site-packages (from transformers) (21.0)\n",
      "Collecting pyyaml>=5.1\n",
      "  Using cached PyYAML-5.4.1-cp36-cp36m-win_amd64.whl (209 kB)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Using cached tokenizers-0.10.3-cp36-cp36m-win_amd64.whl (2.0 MB)\n",
      "Collecting numpy>=1.17\n",
      "  Using cached numpy-1.19.5-cp36-cp36m-win_amd64.whl (13.2 MB)\n",
      "Collecting sacremoses\n",
      "  Using cached sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached regex-2021.7.6-cp36-cp36m-win_amd64.whl (270 kB)\n",
      "Collecting importlib-metadata\n",
      "  Using cached importlib_metadata-4.6.1-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\com\\anaconda3\\envs\\py36_env\\lib\\site-packages (from huggingface-hub==0.0.12->transformers) (3.10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\com\\anaconda3\\envs\\py36_env\\lib\\site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\com\\anaconda3\\envs\\py36_env\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Collecting zipp>=0.5\n",
      "  Using cached zipp-3.5.0-py3-none-any.whl (5.7 kB)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in c:\\users\\com\\anaconda3\\envs\\py36_env\\lib\\site-packages (from requests->transformers) (2.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\com\\anaconda3\\envs\\py36_env\\lib\\site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\com\\anaconda3\\envs\\py36_env\\lib\\site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in c:\\users\\com\\anaconda3\\envs\\py36_env\\lib\\site-packages (from requests->transformers) (1.22)\n",
      "Collecting click\n",
      "  Using cached click-8.0.1-py3-none-any.whl (97 kB)\n",
      "Requirement already satisfied: six in c:\\users\\com\\anaconda3\\envs\\py36_env\\lib\\site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Collecting joblib\n",
      "  Using cached joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "Installing collected packages: zipp, importlib-metadata, tqdm, regex, joblib, filelock, click, tokenizers, sacremoses, pyyaml, numpy, huggingface-hub, transformers\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.16.6\n",
      "    Uninstalling numpy-1.16.6:\n",
      "      Successfully uninstalled numpy-1.16.6\n",
      "Successfully installed click-8.0.1 filelock-3.0.12 huggingface-hub-0.0.12 importlib-metadata-4.6.1 joblib-1.0.1 numpy-1.19.5 pyyaml-5.4.1 regex-2021.7.6 sacremoses-0.0.45 tokenizers-0.10.3 tqdm-4.61.2 transformers-4.9.1 zipp-3.5.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "mxnet 1.7.0.post2 requires numpy<1.17.0,>=1.8.2, but you have numpy 1.19.5 which is incompatible.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\r\n",
    "from kogpt2.pytorch_kogpt2 import get_pytorch_kogpt2_model\r\n",
    "from gluonnlp.data import SentencepieceTokenizer\r\n",
    "from kogpt2.utils import get_tokenizer\r\n",
    "\r\n",
    "tok_path = get_tokenizer()\r\n",
    "model, vocab = get_pytorch_kogpt2_model()\r\n",
    "tok = SentencepieceTokenizer(tok_path)\r\n",
    "sent = '2019년 한해를 보내며,'\r\n",
    "toked = tok(sent)\r\n",
    "while 1:\r\n",
    "  input_ids = torch.tensor([vocab[vocab.bos_token],]  + vocab[toked]).unsqueeze(0)\r\n",
    "  pred = model(input_ids)[0]\r\n",
    "  gen = vocab.to_tokens(torch.argmax(pred, axis=-1).squeeze().tolist())[-1]\r\n",
    "  if gen == '</s>':\r\n",
    "      break\r\n",
    "  sent += gen.replace('▁', ' ')\r\n",
    "  toked = tok(sent)\r\n",
    "sent"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kogpt2'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-3d746071d398>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkogpt2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpytorch_kogpt2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_pytorch_kogpt2_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgluonnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSentencepieceTokenizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkogpt2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_tokenizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'kogpt2'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import gluonnlp as nlp"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gluonnlp'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-e68c3b59001c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgluonnlp\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gluonnlp'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install mxnet"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: mxnet in c:\\users\\com\\anaconda3\\envs\\py36_env\\lib\\site-packages (1.7.0.post2)\n",
      "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in c:\\users\\com\\anaconda3\\envs\\py36_env\\lib\\site-packages (from mxnet) (0.8.4)\n",
      "Requirement already satisfied: numpy<1.17.0,>=1.8.2 in c:\\users\\com\\anaconda3\\envs\\py36_env\\lib\\site-packages (from mxnet) (1.16.6)\n",
      "Requirement already satisfied: requests<2.19.0,>=2.18.4 in c:\\users\\com\\anaconda3\\envs\\py36_env\\lib\\site-packages (from mxnet) (2.18.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in c:\\users\\com\\anaconda3\\envs\\py36_env\\lib\\site-packages (from requests<2.19.0,>=2.18.4->mxnet) (2.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\com\\anaconda3\\envs\\py36_env\\lib\\site-packages (from requests<2.19.0,>=2.18.4->mxnet) (2021.5.30)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\com\\anaconda3\\envs\\py36_env\\lib\\site-packages (from requests<2.19.0,>=2.18.4->mxnet) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in c:\\users\\com\\anaconda3\\envs\\py36_env\\lib\\site-packages (from requests<2.19.0,>=2.18.4->mxnet) (1.22)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import mxnet"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from transformers import PreTrainedTokenizerFast\r\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\r\n",
    "  bos_token='</s>', eos_token='</s>', unk_token='<unk>',\r\n",
    "  pad_token='<pad>', mask_token='<mask>') \r\n",
    "tokenizer.tokenize(\"안녕하세요. 한국어 GPT-2 입니다.😤:)l^o\")\r\n",
    "['▁안녕', '하', '세', '요.', '▁한국어', '▁G', 'P', 'T', '-2', '▁입', '니다.', '😤', ':)', 'l^o']"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading: 100%|██████████| 2.83M/2.83M [00:00<00:00, 3.12MB/s]\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['▁안녕',\n",
       " '하',\n",
       " '세',\n",
       " '요.',\n",
       " '▁한국어',\n",
       " '▁G',\n",
       " 'P',\n",
       " 'T',\n",
       " '-2',\n",
       " '▁입',\n",
       " '니다.',\n",
       " '😤',\n",
       " ':)',\n",
       " 'l^o']"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "import torch\r\n",
    "from transformers import GPT2LMHeadModel\r\n",
    "num = 41\r\n",
    "model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')\r\n",
    "text = '피부의 조직이 괴사된다면'\r\n",
    "input_ids = tokenizer.encode(text)\r\n",
    "gen_ids = model.generate(torch.tensor([input_ids]),\r\n",
    "                           max_length = int(\"{}\".format(num)),\r\n",
    "                           repetition_penalty=1.9,\r\n",
    "                           pad_token_id=tokenizer.pad_token_id,\r\n",
    "                           eos_token_id=tokenizer.eos_token_id,\r\n",
    "                           bos_token_id=tokenizer.bos_token_id,\r\n",
    "                           use_cache=True)\r\n",
    "generated = tokenizer.decode(gen_ids[0,:].tolist())\r\n",
    "\r\n",
    "print(generated)\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "피부의 조직이 괴사된다면 그 원인은 아직 밝혀지지 않았다.\n",
      "그러나 이 같은 사실은 이미 여러 차례 밝혀졌었다.\n",
      "이번 연구에서는 뇌졸중 환자의 약 80%가 알츠하이머병이라는 사실을 밝혀냈다.\n",
      "알\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "generated[-2]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "temperature = 202\r\n",
    "measure = 'Fahrenheit'\r\n",
    "print('Water boils at %d degrees %s' % (temperature, measure))     # 1\r\n",
    "print('Water boils at {} degrees {}'.format(num, measure)) # 2\r\n",
    "print(f'Water boils at {temperature} degrees {measure}') "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Water boils at 202 degrees Fahrenheit\n",
      "Water boils at 30 degrees Fahrenheit\n",
      "Water boils at 202 degrees Fahrenheit\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "import torch\r\n",
    "from transformers import GPT2LMHeadModel\r\n",
    "num = 300\r\n",
    "model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')\r\n",
    "text = '피부의 조직이 괴사된다면'\r\n",
    "input_ids = tokenizer.encode(text)\r\n",
    "while True:\r\n",
    "    gen_ids = model.generate(torch.tensor([input_ids]),\r\n",
    "                            max_length = int(\"{}\".format(num)),\r\n",
    "                            repetition_penalty=1.9,\r\n",
    "                            pad_token_id=tokenizer.pad_token_id,\r\n",
    "                            eos_token_id=tokenizer.eos_token_id,\r\n",
    "                            bos_token_id=tokenizer.bos_token_id,\r\n",
    "                            use_cache=True)\r\n",
    "    generated = tokenizer.decode(gen_ids[0,:].tolist())\r\n",
    "    num += 1\r\n",
    "    print(\"조정중.\")\r\n",
    "    if generated[-1] == \"\\n\":\r\n",
    "        print(generated)\r\n",
    "        break\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "조정중.\n",
      "조정중.\n",
      "조정중.\n",
      "조정중.\n",
      "조정중.\n",
      "조정중.\n",
      "조정중.\n",
      "조정중.\n",
      "조정중.\n",
      "조정중.\n",
      "조정중.\n",
      "조정중.\n",
      "조정중.\n",
      "조정중.\n",
      "조정중.\n",
      "조정중.\n",
      "조정중.\n",
      "피부의 조직이 괴사된다면 그 원인은 아직 밝혀지지 않았다.\n",
      "그러나 이 같은 사실은 이미 여러 차례 밝혀졌었다.\n",
      "이번 연구에서는 뇌졸중 환자의 약 80%가 알츠하이머병이라는 사실을 밝혀냈다.\n",
      "알츠는 신경전달물질인 아세틸콜린의 분비를 촉진해 뇌의 혈류량을 증가시킨다.\n",
      "또한 혈관 내피세포의 기능을 활성화시켜 동맥경화를 예방한다.\n",
      "뇌혈관이 좁아지면 혈액순환에 장애가 생겨 심혈관질환을 유발할 수 있다.\n",
      "따라서 이번 연구는 심장마비나 당뇨병, 고혈압, 고지혈, 비만, 흡연, 음주, 흡연 등 다양한 위험요인을 가진 환자들에게 도움이 될 것으로 기대된다.\n",
      "연구팀은 “심장마비 환자는 대부분 치매나 파킨슨병을 앓고 있는 경우가 많다”며 “이들은 다른 질환과 마찬가지로 조기 발견 및 치료가 중요하다”고 말했다.\n",
      "이어 그는 “아직까지 정확한 원인을 규명하지 못한 상태”라며 “그동안의 연구를 통해 밝혀진 바로는 심근 경색이나 심부전, 협착증, 말초동맥경화 등의 합병증이 발생할 가능성이 높기 때문에 조기에 적절한 치료를 받는 것이 좋다”라고 덧붙였다.</d> 지난달 30일 오후 서울 종로구 세종로 정부중앙청사에서 열린 ‘2010 대한민국 사회공헌대상’ 시상식에서 한국사회복지협의회(회장 박삼구)는 보건복지부 장관상을 수상했다.\n",
      "한국사회봉사단은 사회복지 분야 공익사업을 발굴하고 지원하는 비영리 민간단체다.\n",
      "지난 2005년부터 매년 전국 지방자치단체와 함께 지역사회 소외계층을 위한 봉사활동을 펼치고 있으며, 올해는 총 4억원의 기금을 조성했다.\n",
      "박 회장은 수상 소감을 묻는 기자들의 질문에 대해 “우리 사회가 어려운 이웃들에게 희망을 주는 따뜻한 사회를 만들기 위해 노력하겠다.”고 밝혔다.\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "source": [
    "import torch\r\n",
    "from transformers import GPT2LMHeadModel\r\n",
    "num = 150\r\n",
    "model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')\r\n",
    "text = '원피스, 가히멀티밤, 창문형에어컨, 에어컨실외기커버, 포켓몬카드 '\r\n",
    "input_ids = tokenizer.encode(text)\r\n",
    "while True:\r\n",
    "    gen_ids = model.generate(torch.tensor([input_ids]),\r\n",
    "                            max_length = int(\"{}\".format(num)),\r\n",
    "                            repetition_penalty=1.9,\r\n",
    "                            pad_token_id=tokenizer.pad_token_id,\r\n",
    "                            eos_token_id=tokenizer.eos_token_id,\r\n",
    "                            bos_token_id=tokenizer.bos_token_id,\r\n",
    "                            use_cache=True)\r\n",
    "    generated = tokenizer.decode(gen_ids[0,:].tolist())\r\n",
    "    num += 1\r\n",
    "    print(\"조정중.\")\r\n",
    "    if generated[-1] == \"\\n\":\r\n",
    "        print(generated)\r\n",
    "        break"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "조정중.\n",
      "조정중.\n",
      "조정중.\n",
      "조정중.\n",
      "원피스, 가히멀티밤, 창문형에어컨, 에어컨실외기커버, 포켓몬카드 까지.\n",
      "이런저렇게 다양한 제품들이 출시되고 있지만 정작 소비자들은 이런 제품을 구매하지 않는 경우가 많다.\n",
      "특히나 요즘 같은 날씨에는 실내에서 생활하는 시간이 많아지면서 이러한 제품이 더욱 인기를 끌고 있다.\n",
      "그렇다면 어떤 것이 더 좋은가!\n",
      "바로 '에코백'이다.\n",
      "'아이스박스'는 에코의 백을 모티브로 한 디자인으로 실용성과 기능성을 모두 갖춘 아이템이다.\n",
      "또한 이 제품은 공기청정기와 함께 사용하면 보다 쾌적한 공기를 느낄 수 있어 여름철 필수품으로 자리 잡았다.\n",
      "최근 들어 미세먼지 때문에 외출하기 꺼려지는 사람들이 늘어나면서 집에서 손쉽게 사용할수 있는 홈케어를 위한 수요가 늘고 있기 때문이다.\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('py36_env': conda)"
  },
  "interpreter": {
   "hash": "70f5aa6827e2eaf69aee478d99e62778054691c2f2c3adc8ab20a2da736a645c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}